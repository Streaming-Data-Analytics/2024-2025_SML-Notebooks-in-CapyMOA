{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description \n",
    "\n",
    "In this notebook we demonstrate how someone can directly use scikit-learn learners in CapyMOA and River. In addition, we show how to use Pytorch with CapyMOA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CapyMoa\n",
    "from capymoa.datasets import Electricity\n",
    "from capymoa.evaluation import ClassificationEvaluator, prequential_evaluation\n",
    "from capymoa.base import SKClassifier\n",
    "\n",
    "# River\n",
    "from river.evaluate import progressive_val_score, iter_progressive_val_score\n",
    "from river.stream import iter_sklearn_dataset, iter_pandas, iter_csv\n",
    "from river.metrics import Accuracy\n",
    "from river import compat, linear_model\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn import model_selection, datasets, metrics\n",
    "from sklearn import linear_model as sk_linear_model\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Miscellaneous for tracking\n",
    "import time, tracemalloc, psutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapyMOA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code evaluates the performance of a standard SGDClassifier from scikit-learn using the CapyMOA prequential evaluation framework on the Electricity dataset. The classifier is wrapped using SKClassifier to make it compatible with CapyMOA’s streaming API. The model is evaluated using a sliding window approach (size 4500), and cumulative accuracy is computed to assess its online learning performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.18079096045197"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from capymoa.evaluation import prequential_evaluation\n",
    "\n",
    "# Load the Electricity stream dataset\n",
    "elec_stream = Electricity()\n",
    "\n",
    "# Wrap scikit-learn's SGDClassifier for compatibility with CapyMOA\n",
    "sklearn_SGD = SKClassifier(\n",
    "    schema=elec_stream.get_schema(), sklearner=sk_linear_model.SGDClassifier()\n",
    ")\n",
    "\n",
    "# Perform prequential evaluation using a sliding window of 4500 instances\n",
    "results_sklearn_SGD = prequential_evaluation(\n",
    "    stream=elec_stream, learner=sklearn_SGD, window_size=4500\n",
    ")\n",
    "\n",
    "results_sklearn_SGD.cumulative.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show the same functionality in River. This script performs cross-validation on the sklearn breast cancer dataset. It uses a logistic regression model for binary classification and evaluates its performance using a 5-fold deterministic K-Fold cross-validation. The logistic regression model is converted from a River-compatible format to ensure compatibility with scikit-learn's cross_val_score function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.816 (± 0.158)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# Define a determistic cross-validation procedure\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "\n",
    "# We define a model - Pipeline didn't work\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# We make the model compatible with sklearn\n",
    "model = compat.convert_river_to_sklearn(model)\n",
    "\n",
    "# We compute the CV scores using the same CV scheme and the same scoring\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "\n",
    "# Display the average score and its standard deviation\n",
    "print(f'ROC AUC: {scores.mean():.3f} (± {scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapyMOA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using Pytorch we have to define a simple NeuralNetwork to test the library. A simple architecture with two hidden layers of 512 neurons. In our case, since we are performing classification, we have two neurons for our output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size=0, number_of_classes=0):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, number_of_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can show how to use Pytorch to train our previously defined neural network in a streaming way using has_more_instances(). For each instance we define X, y and we perform prediction/training using the usual torch way of doing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Accuracy at 500 : 56.8\n",
      "Accuracy at 1000 : 59.0\n",
      "Accuracy at 1500 : 62.133333333333326\n",
      "Accuracy at 2000 : 61.85000000000001\n",
      "Accuracy at 2500 : 61.919999999999995\n",
      "Accuracy at 3000 : 62.4\n",
      "Accuracy at 3500 : 62.02857142857143\n",
      "Accuracy at 4000 : 63.24999999999999\n",
      "Accuracy at 4500 : 63.4\n",
      "Accuracy at 5000 : 63.78\n",
      "Accuracy at 5500 : 64.03636363636363\n",
      "Accuracy at 6000 : 64.26666666666667\n",
      "Accuracy at 6500 : 64.61538461538461\n",
      "Accuracy at 7000 : 64.85714285714286\n",
      "Accuracy at 7500 : 64.49333333333334\n",
      "Accuracy at 8000 : 64.2875\n",
      "Accuracy at 8500 : 64.31764705882354\n",
      "Accuracy at 9000 : 64.33333333333333\n",
      "Accuracy at 9500 : 64.13684210526316\n",
      "Accuracy at 10000 : 64.25999999999999\n",
      "Accuracy at 10500 : 64.4095238095238\n",
      "Accuracy at 11000 : 64.4\n",
      "Accuracy at 11500 : 64.3391304347826\n",
      "Accuracy at 12000 : 64.47500000000001\n",
      "Accuracy at 12500 : 64.704\n",
      "Accuracy at 13000 : 64.93846153846154\n",
      "Accuracy at 13500 : 65.02962962962962\n",
      "Accuracy at 14000 : 65.07142857142857\n",
      "Accuracy at 14500 : 65.28275862068965\n",
      "Accuracy at 15000 : 65.52666666666667\n",
      "Accuracy at 15500 : 65.69032258064517\n",
      "Accuracy at 16000 : 65.65625\n",
      "Accuracy at 16500 : 65.81212121212121\n",
      "Accuracy at 17000 : 66.0529411764706\n",
      "Accuracy at 17500 : 66.24\n",
      "Accuracy at 18000 : 66.42777777777778\n",
      "Accuracy at 18500 : 66.6054054054054\n",
      "Accuracy at 19000 : 66.94210526315788\n",
      "Accuracy at 19500 : 67.15897435897435\n",
      "Accuracy at 20000 : 67.49000000000001\n",
      "Accuracy at 20500 : 67.74634146341464\n",
      "Accuracy at 21000 : 67.9047619047619\n",
      "Accuracy at 21500 : 68.1813953488372\n",
      "Accuracy at 22000 : 68.31363636363636\n",
      "Accuracy at 22500 : 68.46222222222222\n",
      "Accuracy at 23000 : 68.63478260869566\n",
      "Accuracy at 23500 : 68.83829787234042\n",
      "Accuracy at 24000 : 69.0625\n",
      "Accuracy at 24500 : 69.33469387755102\n",
      "Accuracy at 25000 : 69.448\n",
      "Accuracy at 25500 : 69.5843137254902\n",
      "Accuracy at 26000 : 69.74615384615385\n",
      "Accuracy at 26500 : 69.95471698113207\n",
      "Accuracy at 27000 : 70.17777777777778\n",
      "Accuracy at 27500 : 70.45454545454545\n",
      "Accuracy at 28000 : 70.56428571428572\n",
      "Accuracy at 28500 : 70.64912280701753\n",
      "Accuracy at 29000 : 70.8103448275862\n",
      "Accuracy at 29500 : 70.99661016949153\n",
      "Accuracy at 30000 : 71.1\n",
      "Accuracy at 30500 : 71.17377049180328\n",
      "Accuracy at 31000 : 71.29677419354839\n",
      "Accuracy at 31500 : 71.27301587301588\n",
      "Accuracy at 32000 : 71.259375\n",
      "Accuracy at 32500 : 71.32615384615384\n",
      "Accuracy at 33000 : 71.43030303030304\n",
      "Accuracy at 33500 : 71.43582089552238\n",
      "Accuracy at 34000 : 71.50294117647059\n",
      "Accuracy at 34500 : 71.5768115942029\n",
      "Accuracy at 35000 : 71.56\n",
      "Accuracy at 35500 : 71.5943661971831\n",
      "Accuracy at 36000 : 71.625\n",
      "Accuracy at 36500 : 71.64383561643835\n",
      "Accuracy at 37000 : 71.62702702702703\n",
      "Accuracy at 37500 : 71.67733333333334\n",
      "Accuracy at 38000 : 71.72368421052632\n",
      "Accuracy at 38500 : 71.82077922077922\n",
      "Accuracy at 39000 : 71.9897435897436\n",
      "Accuracy at 39500 : 72.07088607594937\n",
      "Accuracy at 40000 : 72.2075\n",
      "Accuracy at 40500 : 72.2567901234568\n",
      "Accuracy at 41000 : 72.31951219512194\n",
      "Accuracy at 41500 : 72.39518072289157\n",
      "Accuracy at 42000 : 72.4547619047619\n",
      "Accuracy at 42500 : 72.53176470588235\n",
      "Accuracy at 43000 : 72.6325581395349\n",
      "Accuracy at 43500 : 72.6712643678161\n",
      "Accuracy at 44000 : 72.71363636363637\n",
      "Accuracy at 44500 : 72.78202247191011\n",
      "Accuracy at 45000 : 72.89555555555556\n",
      "Accuracy at 45311 : 72.91827591534064\n"
     ]
    }
   ],
   "source": [
    "# Creating the evaluator\n",
    "evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "i = 0\n",
    "while elec_stream.has_more_instances():\n",
    "    i += 1\n",
    "    instance = elec_stream.next_instance()\n",
    "    if model is None:\n",
    "        moa_instance = instance.java_instance.getData()\n",
    "        # initialize the model and send it to the device\n",
    "        model = NeuralNetwork(\n",
    "            input_size=elec_stream.get_schema().get_num_attributes(),\n",
    "            number_of_classes=elec_stream.get_schema().get_num_classes(),\n",
    "        ).to(device)\n",
    "        # set the optimizer\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "        print(model)\n",
    "\n",
    "    X = torch.tensor(instance.x, dtype=torch.float32)\n",
    "    y = torch.tensor(instance.y_index, dtype=torch.long)\n",
    "    # set the device and add a dimension to the tensor\n",
    "    X, y = torch.unsqueeze(X.to(device), 0), torch.unsqueeze(y.to(device), 0)\n",
    "\n",
    "    # turn off gradient collection for test\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        prediction = torch.argmax(pred)\n",
    "\n",
    "    # update evaluator with predicted class\n",
    "    evaluator.update(instance.y_index, prediction.item())\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Accuracy at {i} : {evaluator.accuracy()}\")\n",
    "\n",
    "print(f\"Accuracy at {i} : {evaluator.accuracy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
